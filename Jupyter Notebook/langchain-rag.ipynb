{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b7564f-eed0-486c-b72d-6657ffc23a8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dependencies\n",
    "%pip install pandas pypdf python-dotenv openai langchain-iris langchain tiktoken langchain-community langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23a28249-c7e6-40f1-b91b-24998cee1d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load OpenAI APIKEY from env\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv('c:\\\\AIWebinar\\\\.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20ea5c6e-ccab-4d10-a292-e98c0ad3b6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# text loading and splitting\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "# IRIS as vector store\n",
    "from langchain_iris import IRISVector\n",
    "\n",
    "# parse response from llm\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e884abb-7210-435e-9e34-8b171c3bebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open llm model\n",
    "llm_model = \"gpt-3.5-turbo\"\n",
    "\n",
    "# load text & split in chunks\n",
    "pdf_path = \"c:\\\\AIWebinar\\\\FHIREmails.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=400, chunk_overlap=20)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "# function to use to calculate vectors (embeddings) from text\n",
    "embeddings = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d8fcb0-cb5a-4af7-8b24-2bec9ddc36a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IRIS connection string\n",
    "username = 'superuser'\n",
    "password = 'SYS' \n",
    "hostname = 'localhost'\n",
    "port = '51787' \n",
    "namespace = 'USER'\n",
    "CONNECTION_STRING = f\"iris://{username}:{password}@{hostname}:{port}/{namespace}\"\n",
    "print(CONNECTION_STRING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a7663a8-7bf0-4933-91b3-df4baf220296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents (vectors from splitted text)\n",
    "# this will create the collection\n",
    "COLLECTION_NAME = \"fhirmemospdf\"\n",
    "\n",
    "db = IRISVector.from_documents(\n",
    "    embedding=embeddings,\n",
    "    documents=docs,\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    connection_string=CONNECTION_STRING,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4b09ae-2237-47f7-a6c4-b869af3e8d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the following if you are connecting to an existing collection\n",
    "#db = IRISVector(\n",
    "#    embedding_function=embeddings,\n",
    "#    collection_name=COLLECTION_NAME,\n",
    "#    connection_string=CONNECTION_STRING,\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e6301b-92aa-4a35-8c2b-d8101eabceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of docs in vector store: {len(db.get()['ids'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179074ef-84a7-4406-936e-1664946f66e8",
   "metadata": {},
   "source": [
    "# Questions & Answers using documents as context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "224f9c51-747f-45e0-9f90-8c858d66e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create llm\n",
    "llm = ChatOpenAI(temperature=0.0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f53b2421-9ff8-455a-a0bc-df70dabc4921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response schema to parse response afterwards\n",
    "rsp_schema = ResponseSchema(\n",
    "    name=\"rsp\",\n",
    "    description=\"response to question\",\n",
    "    type=\"string\"\n",
    ")\n",
    "\n",
    "# prompt response schema\n",
    "response_schemas = [rsp_schema]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "687492ad-6c29-4890-a96f-948a917da3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_template = \"\"\"\\\n",
    "You are a chat bot assistant at our health organization that helps employees with internal company information.\n",
    "Using the context, provide a comprehensible and clear response that will answer the employee's question.\n",
    "Your answer must be in the same language that the question is asked. \n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Use the following context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Do not use any other information.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b3fa93d-bb58-424d-a27f-e3eb0fc9da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build prompt\n",
    "from langchain.prompts import PromptTemplate\n",
    "QA_CHAIN_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"context\", \"query\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    "    template=query_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88efc09f-cf08-4ade-8bb5-2652c30dd6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=db.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\n",
    "        \"verbose\": True,\n",
    "        \"prompt\": QA_CHAIN_PROMPT\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b25358-5bfe-4605-9838-a0dd84a37399",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain(\"On what date did Moshe and Rivka meet to discuss the InterSystems IRIS FHIR Server's architecture in their organization?\")\n",
    "#result = qa_chain(\"When was the final deployment of FHIR server complete?\")\n",
    "\n",
    "#result = qa_chain(\"מתי התקיימה הפגישה בין משה ורבקה לטובת השרתים של אינטרסיסטמס?\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3636d1-1126-4384-aa74-e800b7ef54a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract actual response\n",
    "output_dict = output_parser.parse(result[\"result\"])\n",
    "output_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
